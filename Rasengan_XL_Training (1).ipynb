{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Let it begin boys\")\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q diffusers transformers accelerate\n",
        "!pip install -q peft bitsandbytes datasets safetensors\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Verification\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch\n",
        "import diffusers\n",
        "import transformers\n",
        "import bitsandbytes\n",
        "\n",
        "print(f\"✓ PyTorch: {torch.__version__}\")\n",
        "print(f\"✓ Diffusers: {diffusers.__version__}\")\n",
        "print(f\"✓ Transformers: {transformers.__version__}\")\n",
        "print(f\"✓ CUDA: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "print(\"LFG!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:18:20.481772Z",
          "iopub.execute_input": "2025-11-16T10:18:20.482033Z",
          "iopub.status.idle": "2025-11-16T10:19:49.515789Z",
          "shell.execute_reply.started": "2025-11-16T10:18:20.482008Z",
          "shell.execute_reply": "2025-11-16T10:19:49.514937Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYNAH2OMWY2N",
        "outputId": "4e5a038d-62be-42fa-92f8-abaef6e47d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let it begin boys\n",
            "\n",
            "================================================================================\n",
            "Verification\n",
            "================================================================================\n",
            "✓ PyTorch: 2.8.0+cu126\n",
            "✓ Diffusers: 0.35.2\n",
            "✓ Transformers: 4.57.1\n",
            "✓ CUDA: True\n",
            "✓ GPU: Tesla T4\n",
            "LFG!\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# google colab use\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c0KXsVt0ndTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f4671b-c87b-42a6-9e2f-14dffa6610c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft==0.5.0\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:20:10.253620Z",
          "iopub.execute_input": "2025-11-16T10:20:10.254199Z",
          "iopub.status.idle": "2025-11-16T10:20:12.729223Z",
          "shell.execute_reply.started": "2025-11-16T10:20:10.254164Z",
          "shell.execute_reply": "2025-11-16T10:20:12.728413Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLmGe5FtWY2R",
        "outputId": "a74efc4a-8696-4f79-fab1-ecc98391acfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft==0.5.0 in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (1.11.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.5.0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->peft==0.5.0) (0.36.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate->peft==0.5.0) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate->peft==0.5.0) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate->peft==0.5.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate->peft==0.5.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate->peft==0.5.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate->peft==0.5.0) (2025.10.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.5.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.5.0) (0.22.1)\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"importing stuff\")\n",
        "import os, gc, json, time, math\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass, asdict\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import set_seed\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:20:19.413808Z",
          "iopub.execute_input": "2025-11-16T10:20:19.414620Z",
          "iopub.status.idle": "2025-11-16T10:20:20.673444Z",
          "shell.execute_reply.started": "2025-11-16T10:20:19.414588Z",
          "shell.execute_reply": "2025-11-16T10:20:20.672596Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KB3BWdiWY2S",
        "outputId": "dcbd5305-5b87-4650-ed8c-d18abcaaba73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing stuff\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset tool\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:20:26.133705Z",
          "iopub.execute_input": "2025-11-16T10:20:26.134645Z",
          "iopub.status.idle": "2025-11-16T10:20:27.468858Z",
          "shell.execute_reply.started": "2025-11-16T10:20:26.134616Z",
          "shell.execute_reply": "2025-11-16T10:20:27.468038Z"
        },
        "id": "iPJ1TIwPWY2T"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the version info and all\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Device:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:20:32.976437Z",
          "iopub.execute_input": "2025-11-16T10:20:32.977570Z",
          "iopub.status.idle": "2025-11-16T10:20:32.982039Z",
          "shell.execute_reply.started": "2025-11-16T10:20:32.977538Z",
          "shell.execute_reply": "2025-11-16T10:20:32.981309Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHYGkgawWY2U",
        "outputId": "5321e442-afc7-4429-a4f3-8f3b9875ff2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 | CUDA available: True\n",
            "Device: Tesla T4\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face & PEFT\n",
        "from diffusers import (\n",
        "    AutoencoderKL,\n",
        "    UNet2DConditionModel,\n",
        "    DDPMScheduler,\n",
        "    StableDiffusionXLPipeline\n",
        ")\n",
        "from transformers import CLIPTokenizer, CLIPTextModel, CLIPTextModelWithProjection"
      ],
      "metadata": {
        "id": "ZMRqNQ8Xnrh0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the path on your Drive\n",
        "drive_model_path = \"/content/drive/MyDrive/sdxl-base-1.0\"\n",
        "os.makedirs(drive_model_path, exist_ok=True)\n",
        "print(f\" Downloading and saving base model to: {drive_model_path}\")\n",
        "#define model id\n",
        "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\""
      ],
      "metadata": {
        "id": "G9Deycyrn2bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4787731-21af-46cc-a263-ac8617cb6143"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading and saving base model to: /content/drive/MyDrive/sdxl-base-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saving Tokenizers...\")\n",
        "CLIPTokenizer.from_pretrained(model_id, subfolder=\"tokenizer\").save_pretrained(f\"{drive_model_path}/tokenizer\")\n",
        "CLIPTokenizer.from_pretrained(model_id, subfolder=\"tokenizer_2\").save_pretrained(f\"{drive_model_path}/tokenizer_2\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Saving Scheduler...\")\n",
        "DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\").save_pretrained(f\"{drive_model_path}/scheduler\")\n"
      ],
      "metadata": {
        "id": "6p-LcmXXn2Yf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "9fda9e591998422db646cb272b8e2a8d",
            "0bba6b691fe140b6857b808d4d3bbafc",
            "00e913ef47eb4996a18887c2d78027e8",
            "bfb25ed4a17948168a853109f486e75b",
            "2830f255345e4cf6ba91a2e037b2b6ec",
            "db40cccd3dbc42d5a3786c56259e122e",
            "378a1711af864cc1ad4245adb6128e8f",
            "9d85f545d14644a1b463bda4c2b0e4ae",
            "8b06b8e859ef457a8eb5e2c8b25dba55",
            "8d7d436d30754f34b37b3fd0167d3563",
            "81650680e42f48d49b244fe5a6359423",
            "932ca9ec590044238a653c1091758901",
            "4f8479e9a34f44fe9b1d160370cf7136",
            "be4412dcbad64ab8b455b0647d166642",
            "fbeb3fbd770b4840a7757a7357a424a6",
            "0ed03210e1b14b1b9186ae5a8d6a3f19",
            "dc17292dd846484fb665085d6e25dc54",
            "578859853c7b4385959b56f4cd64563f",
            "ee98f45b3a774d608b534f4da978d9f2",
            "6e3336dc4a574cf198801a03716d6dad",
            "52c5aa2deec9492fa5526cc8cf170afb",
            "82f61fc2cf5b4c1388b572f78659cd72",
            "881edf224aed4b8fbd5a1cc86f931e85",
            "434ce96113fa44e7bec6f64d707e0fb6",
            "91126d0a7e034aadb9754eb256b19e4e",
            "b13137e21f5d4e1dbf4f1ebffb96f268",
            "9b9a29c92cca491082fcb7d6b0de7ca9",
            "5fc98b04a1ca4e3b94f92de93b34d28e",
            "1b13e871f5034e2da3bde4cf59e55516",
            "c05ae9bcdcbf406f866f1353425aa2c4",
            "62952db78db34e978a42a62553840d9c",
            "c4a50aca96e446de90bf706032b34186",
            "cf2967cdde2748f6ba9e5c8af205db96",
            "d6bd7be6e49b41048b0ebfb2b6a8fc10",
            "7dc2b9d961044e38aead7ac9ff322851",
            "ed94b5a733ec488d845a7b4302042a3d",
            "b13c250ba2144de9873b4ceffe40c26f",
            "2bc0a9ae14aa44a5901ca217ae0b0cd4",
            "45c6e03539c44735ab5fb506b344e546",
            "0d71a99cdedf42148a6b061fe31abed0",
            "9786ecd5b681494eaf87e2acee615c01",
            "476149599fa44156807d441d173b95ea",
            "350124cea7764efab55b9a9349b1877e",
            "ef1dca8042044e98aa87ec4049585622",
            "70096788ee1d4f52bf8c2e0b0bf42e1f",
            "b9c8c2d57d924cbeaeff65f08d2b3f83",
            "284720560b544f17ab53a73326ea67cb",
            "72d5f7b2b173424599127cbd4ab28948",
            "7e4c916658194106926b4389dd00eec7",
            "469264f3eea14e3e977c1e02e22e9c33",
            "996c4e6edbda460e96a6305c559b186c",
            "91d4e9ddc9c24af9ba0d49be77957ca5",
            "f2950c90cb9142a098da28601c2941b5",
            "479aac8fdd2a42d3b2d6b0227cd3b44f",
            "cbeccc219ba24ac3adc5d5be093c7246",
            "ee73c03621064fc19cbf88e293a7c25d",
            "0f5a2589cfbe487a8ed59aa0e5f8e788",
            "1311624c8ea74028a437362a795fd30b",
            "9c07caac4f7d457cb930ddfbf4d38aa0",
            "1435626c163f4986acd40d8bed889193",
            "dfa57fb5db994acab1a66d8147319b78",
            "ef940845a06b4ca5897fec4431ac6c9c",
            "8328772557ab4f4a921fe7f4895d621d",
            "66f7e22634ed4195852911d68a15cbf4",
            "adbb110fe608403489dce324117169c0",
            "5a9e219074e84730b5429bba477e57bc",
            "f6e7ad0581ce4155b37455f146f1d000",
            "8b893622e3d844ddb0b0c16791df5d58",
            "356115837ad84b1e944aaa6ab69ef7b1",
            "0c2850d95b4c4b4fa4f9bf3f35cdac31",
            "04ba697a06b64e94a5be629e9ca28bed",
            "44bd28e254134184acbb13969e1fc911",
            "3b9e835f953341e5a1e9b594ed47a015",
            "5ff292cf9f99431ca02154c39c522e8d",
            "fea3c53a594441cd909f5a9927bfa033",
            "8930bb66b12c4893b54fce41dcc269f5",
            "71433931cbf34860a2bbd6bfccb27322"
          ]
        },
        "outputId": "30b90f7b-0ef6-4c7b-ff82-6289c4db3a2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tokenizers...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fda9e591998422db646cb272b8e2a8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "932ca9ec590044238a653c1091758901"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "881edf224aed4b8fbd5a1cc86f931e85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6bd7be6e49b41048b0ebfb2b6a8fc10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70096788ee1d4f52bf8c2e0b0bf42e1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee73c03621064fc19cbf88e293a7c25d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Scheduler...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "scheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6e7ad0581ce4155b37455f146f1d000"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saving Text Encoders...\")\n",
        "CLIPTextModel.from_pretrained(model_id, subfolder=\"text_encoder\", torch_dtype=torch.float16).save_pretrained(f\"{drive_model_path}/text_encoder\")\n",
        "CLIPTextModelWithProjection.from_pretrained(model_id, subfolder=\"text_encoder_2\", torch_dtype=torch.float16).save_pretrained(f\"{drive_model_path}/text_encoder_2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180,
          "referenced_widgets": [
            "a41366024de84ca98fecf2e597b9b1e0",
            "eb214748ad61424890c72c5365183f20",
            "1eb4a99fbe5a40d187e41cd42289cc15",
            "5712edf15548422e95463112e8c486e3",
            "03076a47ce244ef18118aa804725f924",
            "4e411575fc814eea9603518a4be8316f",
            "02a62f42dc894f78a0e4e02e5ffa7f21",
            "5abe764cd9c746a6a72b5e6dbd73e510",
            "8062de9559b949eb843b553b369ca46c",
            "dd1667cfacd44671a4e7639da1e31633",
            "c6f86a4d492d4422b7c1b95f982b3e8a",
            "13e445685056444489c9810c0fb063bc",
            "9767b184ff654ee9b90b732b18d5eef7",
            "70d3bc050ee34b1aa77d621c63608766",
            "60e50fefdeb546fda6b36a5653475e96",
            "d356eb70933445b3a08ded9b4eff3b5d",
            "7c46aae60f2d484b98dbdde54f3ac929",
            "48c6ca9a72404afa81f1cb432515dbd4",
            "32e2cef8e9ee4fc2a5f8f475b3ea2dae",
            "2b3bc38908bd4f68b1e3dfe44f756ce2",
            "fdde5aacd2a949498ab60e0175e2b1d2",
            "9e4431f1bb9c4cf6b3ddc702b4dde475",
            "2086fd4902784ee68289efa06b29cb33",
            "251c68bb15e5470eaab72144d7e6fdfc",
            "f09ba08373cb46188a18bc6941d53f8d",
            "8fd21d2132c34152ae4061221d1db5e6",
            "b16c9983b1784c5e85529b1ec4748e9e",
            "7b5f6c9dbc5e4a9899bef135b0623bfb",
            "e49d21bf068649f590937718a2bf435a",
            "f5a904fd1dfb46138fc6d66b31d98378",
            "9965f999e70248a5a77be543d9854a6a",
            "e065a786e10e42b7beee8d0ce9616aae",
            "aa8b6f2acb064203b6c7b105be641ee8",
            "237d9721936c4224a39dee929498d093",
            "6a3dce5789c44419b68c00a42056ccde",
            "d5e636615e7e49a081f66b23d13398c2",
            "05c78f0d30b345c8aae10940648d760e",
            "ad1fe77aa4f94ef9a9453f0367565202",
            "925735631abc4bc68ed20b7e7b8dfa2c",
            "f74ef951755d4dedaa5eaa0c9bbbc434",
            "a7023d16e6704bc99e54991e37309628",
            "288f8e449dae4ec5b3c8b42527593f88",
            "c003ddf2375947a38ff504ff22286449",
            "6a86ad36b26e422a85ba21734eb0d33e"
          ]
        },
        "id": "sKHF6RGcBrWy",
        "outputId": "8228fa4e-699e-4832-8445-38e8423df6c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Text Encoders...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a41366024de84ca98fecf2e597b9b1e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "text_encoder/model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13e445685056444489c9810c0fb063bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2086fd4902784ee68289efa06b29cb33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "text_encoder_2/model.safetensors:   0%|          | 0.00/2.78G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "237d9721936c4224a39dee929498d093"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saving VAE...\")\n",
        "AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\", torch_dtype=torch.float32).save_pretrained(f\"{drive_model_path}/vae\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "1d2ad4632d05425388ed9c41d5fa2c6c",
            "7a64b0cda9c948b68369d552019238e0",
            "4628d698a591437db7b3fbe9760b2ec9",
            "d8ae0e4a3ebe4983b03980c02e53a572",
            "df7264ed90374fb5bd97b7354546de4a",
            "b232f1e0b1ab499fa5f87b72243e36ab",
            "fc2a3543b7434ab99a6fb5cc3c1b7e01",
            "eabacffd759f4c82acd371ed96567c93",
            "1de8e79045fb4ae2b64da5d71e989dea",
            "c66aeeb20b9048b09d00645deb1381b7",
            "6b752a6d6acb40bd8f5f5d4609b0547a",
            "6e28107d8ba94a39a32767edf2a0eec5",
            "789568b8085f4abcac734521fbf48438",
            "0d799e6e1464403696b5fc276c44b86c",
            "70edb163525744a786f9b8150c0e5d08",
            "f51eb372391c4822906021dd45ecfdf6",
            "58a099d5dd4a4faba9ce9f490691a951",
            "6e65be513a95476dada7cc2e6c90b6c7",
            "a31a2390664a4a8888bcbd1d1fb3ee98",
            "48b9281c10a64955bb54f69cf837e046",
            "ac5e4869b4914977aa31deb9f55235a0",
            "05cf930827804aeb92e8d81734bca6c9"
          ]
        },
        "id": "dakxYBOlBvKi",
        "outputId": "eab18579-1bdf-41a7-c5a4-8709679a6b9c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving VAE...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d2ad4632d05425388ed9c41d5fa2c6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vae/diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e28107d8ba94a39a32767edf2a0eec5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saving UNet\")\n",
        "UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\", torch_dtype=torch.float16).save_pretrained(f\"{drive_model_path}/unet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "ac2cbe3171094173b46db57cb247a418",
            "1e9a4c9b4eb844ec91f0e441cf2295f4",
            "131545e6fca64404be69833667f0df56",
            "386990a7c4614ba7a3c286f7d10eb172",
            "cf8fb5246a764fe2b0043c52f63d9ddf",
            "3ffd9a89618c4bfeb187be08b8b71a10",
            "bbdf51e4441d4407a59f481bec7d39da",
            "b8a07a28b792458cb49b09c70d808023",
            "93283e9b691448cd90b1154e5a0fc9d6",
            "24311b2751fc44d0a35f3cb44be92f21",
            "059a742df00549a5bfe6892e45cf9703",
            "645784ac0fa04e4394b25fcbd433a841",
            "a71696230fd84136ba69b1afce49b26e",
            "2ffd9db33ebb4a1c86a666fb2e0bb09b",
            "9e07f9be08c8451a8ec70cee368de8f1",
            "065ae5ec6e914113972cd3429345ea1c",
            "5cb391713f754014aef014b2b31ec199",
            "44f8e8be31f646c2aaa7bb035b7fc0aa",
            "80b6fb00303d440e9cc508fc07694211",
            "8c48cf0ff5e94369a605e5fe88af09a2",
            "173fd510b3a84d7dbedf93889287afe0",
            "1ac8f6ed50724770999596b2a5882fe5"
          ]
        },
        "id": "-_TEBBlABKya",
        "outputId": "197483c5-2a8d-4ba8-a36b-4e796f23d0a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving UNet\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac2cbe3171094173b46db57cb247a418"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unet/diffusion_pytorch_model.safetensors:   0%|          | 0.00/10.3G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "645784ac0fa04e4394b25fcbd433a841"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training configurations\n",
        "@dataclass\n",
        "class TraininigConfiguration:\n",
        "  modelId: str = \"/content/drive/MyDrive/sdxl-base-1.0\"\n",
        "  datasetId: str = \"lambdalabs/naruto-blip-captions\"\n",
        "  #establish the output directories where we will have output, logs and checkpoints\n",
        "  outputDir: str = \"/content/drive/MyDrive/Naruto_FineTune/output\"\n",
        "  logsDir: str = \"/content/drive/MyDrive/Naruto_FineTune/logs\"\n",
        "  checkpointsDir: str = \"/content/drive/MyDrive/Naruto_FineTune/checkpoints\"\n",
        "  #Training Hyperparamters\n",
        "  resolution: int = 512\n",
        "  train_batch_size: int = 1 #in docs\n",
        "  gradient_accumulation_steps: int = 4\n",
        "  num_train_epochs: int = 3\n",
        "  learning_rate: float = 1e-4\n",
        "  learning_rate_warmup_steps: int = 10\n",
        "  learning_rate_scheduler_type: str = \"cosine\"\n",
        "\n",
        "\n",
        "  # Optimizations\n",
        "  mixed_precision: str = \"fp16\"\n",
        "  grad_checkpointing : bool = True\n",
        "  use_8bit_adam: bool = True\n",
        "  max_grad_norm: float = 1.0\n",
        "\n",
        "  #For a quick dry run let us set some dataset limits that will be used later\n",
        "  max_train_samples: int = 150\n",
        "  seed: int = 42\n",
        "\n",
        "  #checkpoints\n",
        "  save_every_step = 250\n",
        "\n",
        "  #peft;\n",
        "  # PEFT (LoRA/DoRA)\n",
        "  lora_rank: int = 16\n",
        "  lora_alpha: int = 32\n",
        "  lora_dropout: float = 0.1\n",
        "  lora_target_modules: tuple = (\"to_q\",\"to_k\",\"to_v\",\"to_out.0\")\n",
        "\n",
        "  #debug\n",
        "  debug: bool = True\n",
        "  dry_run_steps: int = 15\n",
        "  mini_dataset_mode: bool = False #do set to false when you have to for the entire dataset for the final fine tuning\n",
        "\n",
        "config = TraininigConfiguration()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:21:01.383898Z",
          "iopub.execute_input": "2025-11-16T10:21:01.384440Z",
          "iopub.status.idle": "2025-11-16T10:21:01.391906Z",
          "shell.execute_reply.started": "2025-11-16T10:21:01.384417Z",
          "shell.execute_reply": "2025-11-16T10:21:01.390950Z"
        },
        "id": "50zHd4EhWY2V"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and dataloader prep\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import InterpolationMode"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:21:12.804015Z",
          "iopub.execute_input": "2025-11-16T10:21:12.804597Z",
          "iopub.status.idle": "2025-11-16T10:21:12.808070Z",
          "shell.execute_reply.started": "2025-11-16T10:21:12.804573Z",
          "shell.execute_reply": "2025-11-16T10:21:12.807350Z"
        },
        "id": "YU85oyWoWY2V"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(config.datasetId, split = \"train\")\n",
        "if config.mini_dataset_mode:\n",
        "    print(f\"Training using the mini dataset as the mini dataset mode is set to true in the config and we weiil use the first {config.max_train_samples} samples out of {len(ds)}\")\n",
        "    ds = ds.select(range(config.max_train_samples))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:21:19.434294Z",
          "iopub.execute_input": "2025-11-16T10:21:19.434978Z",
          "iopub.status.idle": "2025-11-16T10:21:27.769241Z",
          "shell.execute_reply.started": "2025-11-16T10:21:19.434956Z",
          "shell.execute_reply": "2025-11-16T10:21:27.768681Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "bf475b9bbbe84935971014480abd7535",
            "d06968670f4b413c933d600a1d811909",
            "53199ab094fd4c63bb936a1446534c0e",
            "3a80a752045a4c72b970011824991df3",
            "a94aacd7167d4785a154aff5fb69965b",
            "8c41f24d15b24465af714470544392ca",
            "72a67c2cd31644619b5bb314a86b1d20",
            "b17c2c75a7bb4e6683cc830953408808",
            "ca49ea4b2e064109aab5d14f667f1918",
            "c150a2fd5fd8454a932272d2943fffd8",
            "3f01297c0f87481585a0dda410a65d61",
            "e04ac5d1bb804e6c806c3c539b1c00ff",
            "cea6350dfa3b45f4b323a6abc4debb06",
            "555a07d9f1d74625a5c2f74b4fd3ddd8",
            "2636c1031e774db5b1a2ba9e7b357135",
            "349cea479e8545ec84f4f96062b9b8f4",
            "c5c3911413bd4556a94c17b0c9154e58",
            "f06be09d018941b5af16accc6ee98fcb",
            "f6a971d33a344f90a0191e9145705fb5",
            "c5d4eabbdc2844f6b446e928e84624ac",
            "de604bd691454333b499ad4b0d0708e9",
            "1269c242819549dcbe5b6a2f3b77c225",
            "5e76df5ac40a40fdb1269bc83493ed58",
            "221bea37c55148719cfb8b783367fd18",
            "c4f6335ae689474eaa534209ae0cae83",
            "e9f7c0e77099422ea9fcc632f3ab6272",
            "5ad8d9a26d9c428f9e8adab9fe37e86b",
            "b9332d16f7f446adb4e232c8c3c569ce",
            "9f856d2fd3fc4f35a3964bc4a2e62eda",
            "3fcced96a1684e5b9fb865f42ed1f55e",
            "21956338c86e4bfcb1f6c5b9f0c08f44",
            "d7be16da50ed481086934dff1b54c707",
            "a78ed1e128e245a294df27c38152c6f9",
            "fea1c45c516a418f9f3fc5b3487f1a57",
            "022ee0154c7146f8b04af1bbff746f94",
            "95c45a8b33154452a90122658592a529",
            "4d214794c0cd4e098d981445f0d731cf",
            "55d43e756491443daf0666b5d04b5f05",
            "cf6ddc861c2f4fb8a5a9ffcb9896a404",
            "6a48a2ff0f394cdfa388f8d0f64d9b85",
            "9bf3317405fb47a58ffac1a7de9781df",
            "f9519695f56742eda62238fbbbd4c1c9",
            "f726b13c25c04dbda35ac5bb96f2f75a",
            "8ee1c4387b094c109e3a26129090c78e",
            "cd7cc174467d4cdda332207a0f41f990",
            "507ef7538ee94ab887a93cfab4da781b",
            "62d0fe3d590543c899692ba45b1e55a6",
            "d2b6ebd5366d4a35972223abac23954a",
            "108827b8ad0f4e6298dba5673e15f2d6",
            "30a97b8472cc48daa7e202817fdbd62f",
            "f005fd106fe1442dbd79f7c318c928da",
            "8dd7f50c21b94717aa5c9f00659d1199",
            "a2281712e62a41c8b9fb780f8194cd2f",
            "a4452e3f1084447d8497cb6e4c4693b9",
            "80c9666147c945fcbd7e0d903d152543"
          ]
        },
        "id": "fvtGLI74WY2W",
        "outputId": "d30b844a-7e65-4038-ce68-0b3b1a01a777"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf475b9bbbe84935971014480abd7535"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "dataset_infos.json:   0%|          | 0.00/897 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e04ac5d1bb804e6c806c3c539b1c00ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00002-12944970063701(…):   0%|          | 0.00/344M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e76df5ac40a40fdb1269bc83493ed58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00002-cefa2f480689f1(…):   0%|          | 0.00/357M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fea1c45c516a418f9f3fc5b3487f1a57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1221 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd7cc174467d4cdda332207a0f41f990"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "if config.max_train_samples is not None:\n",
        "    raw_ds = ds.select(range(min(config.max_train_samples, len(ds))))\n",
        "print(f\"Dataset size: {len(ds)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:21:38.004204Z",
          "iopub.execute_input": "2025-11-16T10:21:38.005234Z",
          "iopub.status.idle": "2025-11-16T10:21:38.012149Z",
          "shell.execute_reply.started": "2025-11-16T10:21:38.005199Z",
          "shell.execute_reply": "2025-11-16T10:21:38.011389Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOpOODnPWY2W",
        "outputId": "0496ff90-f759-487e-a0de-ebe003e9bedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1221\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "example_of_dataset = ds[0]\n",
        "print('it looks something like this', example_of_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:21:49.195875Z",
          "iopub.execute_input": "2025-11-16T10:21:49.196126Z",
          "iopub.status.idle": "2025-11-16T10:21:49.258224Z",
          "shell.execute_reply.started": "2025-11-16T10:21:49.196107Z",
          "shell.execute_reply": "2025-11-16T10:21:49.257504Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoD6-eljWY2X",
        "outputId": "7bf6c2b9-0467-4ba1-cb38-c25af135de37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it looks something like this {'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1080x1080 at 0x7BC53281F0B0>, 'text': 'a man with dark hair and brown eyes'}\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "print('it looks something like this', example_of_dataset.keys())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:21:56.853699Z",
          "iopub.execute_input": "2025-11-16T10:21:56.854459Z",
          "iopub.status.idle": "2025-11-16T10:21:56.858593Z",
          "shell.execute_reply.started": "2025-11-16T10:21:56.854431Z",
          "shell.execute_reply": "2025-11-16T10:21:56.857799Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvycYvjRWY2X",
        "outputId": "f3249787-6e0b-4e4d-d26a-2cb519643ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it looks something like this dict_keys(['image', 'text'])\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "print('it looks something like this', example_of_dataset.get('text'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:22:03.133773Z",
          "iopub.execute_input": "2025-11-16T10:22:03.134081Z",
          "iopub.status.idle": "2025-11-16T10:22:03.138073Z",
          "shell.execute_reply.started": "2025-11-16T10:22:03.134062Z",
          "shell.execute_reply": "2025-11-16T10:22:03.137367Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1oMvfvTWY2X",
        "outputId": "50a9c71d-2e3e-4490-c480-ac98b646c6c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it looks something like this a man with dark hair and brown eyes\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizers\n",
        "tokenizer_one = CLIPTokenizer.from_pretrained(config.modelId, subfolder=\"tokenizer\")\n",
        "tokenizer_two = CLIPTokenizer.from_pretrained(config.modelId, subfolder=\"tokenizer_2\")\n",
        "print(\"Tokenizers loaded.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:25:30.584281Z",
          "iopub.execute_input": "2025-11-16T10:25:30.584963Z",
          "iopub.status.idle": "2025-11-16T10:25:31.556394Z",
          "shell.execute_reply.started": "2025-11-16T10:25:30.584933Z",
          "shell.execute_reply": "2025-11-16T10:25:31.555562Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsWuzKT7WY2Y",
        "outputId": "0588f42e-44d4-47c0-87b7-66b7c41b0636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizers loaded.\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset class\n",
        "class DatasetOfNaruto(Dataset):\n",
        "  def __init__(self,hf_dataset,tokenizer_one,tokenizer_two, resolution=512):\n",
        "    self.ds = hf_dataset\n",
        "    self.tokenizer_1 = tokenizer_one\n",
        "    self.tokenizer_2 = tokenizer_two\n",
        "    self.resolution= resolution\n",
        "    self.transform = T.Compose([\n",
        "      T.Resize((resolution, resolution), interpolation=InterpolationMode.BILINEAR),\n",
        "      T.CenterCrop((resolution, resolution)),\n",
        "      T.RandomHorizontalFlip(p=0.5),\n",
        "      T.ToTensor(),\n",
        "      T.Normalize([0.5]*3, [0.5]*3)\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ds)\n",
        "\n",
        "  def tokenizer_captions(self,text):\n",
        "    tok_caption_1 = self.tokenizer_1(text, padding=\"max_length\", truncation=True, max_length=self.tokenizer_1.model_max_length, return_tensors=\"pt\")\n",
        "    tok_caption_2 = self.tokenizer_2(text, padding=\"max_length\", truncation=True, max_length=self.tokenizer_2.model_max_length, return_tensors=\"pt\")\n",
        "    return tok_caption_1.input_ids.squeeze(0), tok_caption_2.input_ids.squeeze(0)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    item = self.ds[idx]\n",
        "    img = item[\"image\"]\n",
        "    pixel_values = self.transform(img)\n",
        "    caption = item.get(\"text\") or item.get(\"caption\") or item.get(\"title\") or \"\"\n",
        "    ids1, ids2 = self.tokenizer_captions(caption)\n",
        "    return {\"pixel_values\": pixel_values, \"input_ids_one\": ids1, \"input_ids_two\": ids2, \"caption\": caption}\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:25:33.583863Z",
          "iopub.execute_input": "2025-11-16T10:25:33.584452Z",
          "iopub.status.idle": "2025-11-16T10:25:33.595014Z",
          "shell.execute_reply.started": "2025-11-16T10:25:33.584428Z",
          "shell.execute_reply": "2025-11-16T10:25:33.594012Z"
        },
        "id": "jAu8hvT5WY2Y"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset and dataloader\n",
        "train_ds = DatasetOfNaruto(ds, tokenizer_one, tokenizer_two, resolution=config.resolution)\n",
        "train_loader = DataLoader(train_ds, batch_size=config.train_batch_size, shuffle = True, num_workers = 2, pin_memory=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:25:33.883973Z",
          "iopub.execute_input": "2025-11-16T10:25:33.884754Z",
          "iopub.status.idle": "2025-11-16T10:25:33.914768Z",
          "shell.execute_reply.started": "2025-11-16T10:25:33.884721Z",
          "shell.execute_reply": "2025-11-16T10:25:33.914006Z"
        },
        "id": "hA9oWQXvWY2Z"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataloader ready. Number of batches per epoch:\", len(train_loader))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:25:35.023889Z",
          "iopub.execute_input": "2025-11-16T10:25:35.024621Z",
          "iopub.status.idle": "2025-11-16T10:25:35.028733Z",
          "shell.execute_reply.started": "2025-11-16T10:25:35.024595Z",
          "shell.execute_reply": "2025-11-16T10:25:35.027870Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG6-KZzqWY2Z",
        "outputId": "13d260ba-9a3d-40bb-8184-cf71870880e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloader ready. Number of batches per epoch: 1221\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(\"Batch keys:\", batch.keys())\n",
        "print(\"Pixel values shape:\", batch[\"pixel_values\"].shape)\n",
        "print(\"Caption (first):\", batch[\"caption\"][0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:25:35.303899Z",
          "iopub.execute_input": "2025-11-16T10:25:35.304619Z",
          "iopub.status.idle": "2025-11-16T10:25:35.666291Z",
          "shell.execute_reply.started": "2025-11-16T10:25:35.304588Z",
          "shell.execute_reply": "2025-11-16T10:25:35.665403Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcAeoSa8WY2Z",
        "outputId": "4843daee-e851-4291-cb3d-b773465e498e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch keys: dict_keys(['pixel_values', 'input_ids_one', 'input_ids_two', 'caption'])\n",
            "Pixel values shape: torch.Size([1, 3, 512, 512])\n",
            "Caption (first): a man in a white shirt and vest\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the models\n",
        "from diffusers import UNet2DConditionModel, AutoencoderKL, DDPMScheduler\n",
        "from transformers import CLIPTextModel, CLIPTextModelWithProjection"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:25:36.544458Z",
          "iopub.execute_input": "2025-11-16T10:25:36.545078Z",
          "iopub.status.idle": "2025-11-16T10:25:36.549786Z",
          "shell.execute_reply.started": "2025-11-16T10:25:36.545039Z",
          "shell.execute_reply": "2025-11-16T10:25:36.548982Z"
        },
        "id": "Xs9labPEWY2Z"
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "#load the text encoders\n",
        "text_encoder_1 = CLIPTextModel.from_pretrained(config.modelId, subfolder=\"text_encoder\", torch_dtype = torch.float16, device_map=\"cpu\")\n",
        "text_encoder_2 = CLIPTextModel.from_pretrained(config.modelId, subfolder=\"text_encoder_2\", torch_dtype = torch.float16, device_map=\"cpu\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:25:36.913775Z",
          "iopub.execute_input": "2025-11-16T10:25:36.914607Z",
          "iopub.status.idle": "2025-11-16T10:25:44.552237Z",
          "shell.execute_reply.started": "2025-11-16T10:25:36.914582Z",
          "shell.execute_reply": "2025-11-16T10:25:44.551405Z"
        },
        "id": "-NPwJdzOWY2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bafb1c5-ff39-4668-fe80-cf9ff5b2b903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "acc = Accelerator(\n",
        "    gradient_accumulation_steps = config.gradient_accumulation_steps,\n",
        "    mixed_precision=config.mixed_precision,\n",
        ")"
      ],
      "metadata": {
        "id": "ofAfI9jaHQ86"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = AutoencoderKL.from_pretrained(\n",
        "    config.modelId,\n",
        "    subfolder=\"vae\",\n",
        "    torch_dtype=torch.float32,   # MUST be float32\n",
        ")\n",
        "vae.requires_grad_(False)\n",
        "vae.to(acc.device) #to be noted that this VAE is the worst piece of thing ever - needs to be trained on the gpu but make sure that the dtype is float32 and not 16 -> this will cause mismatch error in data types if you do this -> personal notes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:49:42.501069Z",
          "iopub.execute_input": "2025-11-16T10:49:42.501374Z",
          "iopub.status.idle": "2025-11-16T10:49:42.825026Z",
          "shell.execute_reply.started": "2025-11-16T10:49:42.501356Z",
          "shell.execute_reply": "2025-11-16T10:49:42.824398Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3bp3xCsWY2a",
        "outputId": "b08b0511-90ca-4840-d56e-5f043818e0c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoencoderKL(\n",
              "  (encoder): Encoder(\n",
              "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (down_blocks): ModuleList(\n",
              "      (0): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0-1): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (downsamplers): ModuleList(\n",
              "          (0): Downsample2D(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (downsamplers): ModuleList(\n",
              "          (0): Downsample2D(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (downsamplers): ModuleList(\n",
              "          (0): Downsample2D(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): DownEncoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0-1): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (mid_block): UNetMidBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0): Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "    (conv_act): SiLU()\n",
              "    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (up_blocks): ModuleList(\n",
              "      (0-1): 2 x UpDecoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0-2): 3 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (upsamplers): ModuleList(\n",
              "          (0): Upsample2D(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): UpDecoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "        (upsamplers): ModuleList(\n",
              "          (0): Upsample2D(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): UpDecoderBlock2D(\n",
              "        (resnets): ModuleList(\n",
              "          (0): ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "            (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x ResnetBlock2D(\n",
              "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (nonlinearity): SiLU()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (mid_block): UNetMidBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0): Attention(\n",
              "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (to_out): ModuleList(\n",
              "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (1): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "    (conv_act): SiLU()\n",
              "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "#load the unet\n",
        "unet = UNet2DConditionModel.from_pretrained(config.modelId, subfolder=\"unet\", torch_dtype=torch.float16, device_map=\"cpu\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:26:19.553954Z",
          "iopub.execute_input": "2025-11-16T10:26:19.554671Z",
          "iopub.status.idle": "2025-11-16T10:27:12.162014Z",
          "shell.execute_reply.started": "2025-11-16T10:26:19.554645Z",
          "shell.execute_reply": "2025-11-16T10:27:12.161208Z"
        },
        "id": "KZIOe2R8WY2a"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "#noise scheduler\n",
        "noise_scheduler = DDPMScheduler.from_pretrained(config.modelId, subfolder=\"scheduler\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:27:12.163562Z",
          "iopub.execute_input": "2025-11-16T10:27:12.163805Z",
          "iopub.status.idle": "2025-11-16T10:27:12.346497Z",
          "shell.execute_reply.started": "2025-11-16T10:27:12.163789Z",
          "shell.execute_reply": "2025-11-16T10:27:12.345750Z"
        },
        "id": "NzsAMRLjWY2a"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "#now we will freeze te1, te1 and vae\n",
        "for p in text_encoder_1.parameters():\n",
        "  p.requires_grad=False\n",
        "for p in text_encoder_2.parameters():\n",
        "  p.requires_grad=False\n",
        "\n",
        "for p in vae.parameters():\n",
        "  p.requires_grad=False\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:27:23.283877Z",
          "iopub.execute_input": "2025-11-16T10:27:23.284160Z",
          "iopub.status.idle": "2025-11-16T10:27:23.291336Z",
          "shell.execute_reply.started": "2025-11-16T10:27:23.284138Z",
          "shell.execute_reply": "2025-11-16T10:27:23.290530Z"
        },
        "id": "yiWSR1WHWY2a"
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:27:29.744277Z",
          "iopub.execute_input": "2025-11-16T10:27:29.744998Z",
          "iopub.status.idle": "2025-11-16T10:27:29.749347Z",
          "shell.execute_reply.started": "2025-11-16T10:27:29.744965Z",
          "shell.execute_reply": "2025-11-16T10:27:29.748337Z"
        },
        "id": "o66VlFlpWY2a"
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": [
        "def cuda_mem_report(prefix=\"\"):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"{prefix} Allocated: {torch.cuda.memory_allocated() / 1e9:.3f} GB | Reserved: {torch.cuda.memory_reserved() / 1e9:.3f} GB\")\n",
        "    else:\n",
        "        print(f\"{prefix} No CUDA available\")\n",
        "\n",
        "cuda_mem_report(\"After imports:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9-hxjfNHnw0",
        "outputId": "a927fa79-313c-4600-9344-067b5ba18850"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After imports: Allocated: 0.336 GB | Reserved: 0.373 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    print(\"Moving Unet to GPU\")\n",
        "    unet.to(device=device)\n",
        "    cuda_mem_report(\"After moving UNet:\")\n",
        "except RuntimeError as e:\n",
        "    print(\"Well damn, out of memory error!!!!!!!!!!\", e)\n",
        "    unet.to(device=\"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:27:36.053993Z",
          "iopub.execute_input": "2025-11-16T10:27:36.054337Z",
          "iopub.status.idle": "2025-11-16T10:27:37.940471Z",
          "shell.execute_reply.started": "2025-11-16T10:27:36.054312Z",
          "shell.execute_reply": "2025-11-16T10:27:37.939663Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giUrHsVIWY2b",
        "outputId": "16c34efa-8500-4cb3-91e8-6bb256845280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving Unet to GPU\n",
            "After moving UNet: Allocated: 5.578 GB | Reserved: 5.761 GB\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "if config.grad_checkpointing:\n",
        "    try:\n",
        "        unet.enable_gradient_checkpointing()\n",
        "        print(\"Gradient Checpointting is enabled on the UNet - Nice!\")\n",
        "    except Exception as e:\n",
        "        print(\"Not enabled!!!!!!:\", e)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:27:43.083585Z",
          "iopub.execute_input": "2025-11-16T10:27:43.084137Z",
          "iopub.status.idle": "2025-11-16T10:27:43.094658Z",
          "shell.execute_reply.started": "2025-11-16T10:27:43.084105Z",
          "shell.execute_reply": "2025-11-16T10:27:43.093906Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8hW7AOBWY2b",
        "outputId": "d02fc78a-1d50-453e-b336-e3569c650842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Checpointting is enabled on the UNet - Nice!\n"
          ]
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_parameters = sum(p.numel() for p in unet.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters are :\", trainable_parameters)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:28:06.184264Z",
          "iopub.execute_input": "2025-11-16T10:28:06.184935Z",
          "iopub.status.idle": "2025-11-16T10:28:06.193782Z",
          "shell.execute_reply.started": "2025-11-16T10:28:06.184911Z",
          "shell.execute_reply": "2025-11-16T10:28:06.193010Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCFjJFZ9WY2b",
        "outputId": "34014fde-bcd2-4de6-b1b2-4b122ca0340f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable parameters are : 2567463684\n"
          ]
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:28:20.005649Z",
          "iopub.execute_input": "2025-11-16T10:28:20.006363Z",
          "iopub.status.idle": "2025-11-16T10:28:20.009964Z",
          "shell.execute_reply.started": "2025-11-16T10:28:20.006337Z",
          "shell.execute_reply": "2025-11-16T10:28:20.009234Z"
        },
        "id": "kRt9pugrWY2c"
      },
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PEFT techniques to the model - https://huggingface.co/docs/peft/en/package_reference/lora\n",
        "print(\"LORAAAAAAAAA\")\n",
        "#Build LoraConfig\n",
        "lora_config=LoraConfig(\n",
        "    r=config.lora_rank,\n",
        "    lora_alpha= config.lora_alpha,\n",
        "    target_modules = list(config.lora_target_modules),\n",
        "    lora_dropout = config.lora_dropout,\n",
        "    bias=\"none\",\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:28:25.704028Z",
          "iopub.execute_input": "2025-11-16T10:28:25.704307Z",
          "iopub.status.idle": "2025-11-16T10:28:25.708993Z",
          "shell.execute_reply.started": "2025-11-16T10:28:25.704289Z",
          "shell.execute_reply": "2025-11-16T10:28:25.708363Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLmReRrLWY2c",
        "outputId": "f9670bc7-12a1-460f-c77a-da55d9b3ce32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LORAAAAAAAAA\n"
          ]
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "unet = get_peft_model(unet, lora_config)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:28:32.624184Z",
          "iopub.execute_input": "2025-11-16T10:28:32.624924Z",
          "iopub.status.idle": "2025-11-16T10:28:44.191106Z",
          "shell.execute_reply.started": "2025-11-16T10:28:32.624886Z",
          "shell.execute_reply": "2025-11-16T10:28:44.190507Z"
        },
        "id": "bSUl8LQ0WY2c"
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_after = sum(p.numel() for p in unet.parameters() if p.requires_grad)\n",
        "total_after = sum(p.numel() for p in unet.parameters())\n",
        "print(f\"UNet trainable params after PEFT: {trainable_after:,} / {total_after:,} ({100*trainable_after/total_after:.4f}%)\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:28:47.343850Z",
          "iopub.execute_input": "2025-11-16T10:28:47.344122Z",
          "iopub.status.idle": "2025-11-16T10:28:47.376051Z",
          "shell.execute_reply.started": "2025-11-16T10:28:47.344105Z",
          "shell.execute_reply": "2025-11-16T10:28:47.375460Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1I0DwIqWY2c",
        "outputId": "ab0a4719-ea9b-4b53-acb8-04a0dddadaf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet trainable params after PEFT: 23,224,320 / 2,590,688,004 (0.8965%)\n"
          ]
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": [
        "#oprtimizer and scheduler\n",
        "from transformers import get_scheduler"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:29:03.364510Z",
          "iopub.execute_input": "2025-11-16T10:29:03.365123Z",
          "iopub.status.idle": "2025-11-16T10:29:03.395375Z",
          "shell.execute_reply.started": "2025-11-16T10:29:03.365100Z",
          "shell.execute_reply": "2025-11-16T10:29:03.394664Z"
        },
        "id": "9O2bd8lTWY2d"
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": [
        "device = acc.device\n",
        "print(\"Accelerator device:\", device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:29:15.163858Z",
          "iopub.execute_input": "2025-11-16T10:29:15.164115Z",
          "iopub.status.idle": "2025-11-16T10:29:15.168228Z",
          "shell.execute_reply.started": "2025-11-16T10:29:15.164098Z",
          "shell.execute_reply": "2025-11-16T10:29:15.167457Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Vig4LZWY2d",
        "outputId": "bef39667-8981-4d1d-81fd-5aa7c33968e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accelerator device: cuda\n"
          ]
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": [
        "import bitsandbytes as bnb"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:29:31.923900Z",
          "iopub.execute_input": "2025-11-16T10:29:31.924673Z",
          "iopub.status.idle": "2025-11-16T10:29:31.928282Z",
          "shell.execute_reply.started": "2025-11-16T10:29:31.924650Z",
          "shell.execute_reply": "2025-11-16T10:29:31.927446Z"
        },
        "id": "_o78yCCeWY2e"
      },
      "outputs": [],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": [
        "if config.use_8bit_adam:\n",
        "  import bitsandbytes as bnb\n",
        "  optm = bnb.optim.AdamW8bit(unet.parameters(), lr=config.learning_rate)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:29:35.193935Z",
          "iopub.execute_input": "2025-11-16T10:29:35.194674Z",
          "iopub.status.idle": "2025-11-16T10:29:35.215017Z",
          "shell.execute_reply.started": "2025-11-16T10:29:35.194649Z",
          "shell.execute_reply": "2025-11-16T10:29:35.214332Z"
        },
        "id": "Q8JJz_hHWY2k"
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "source": [
        "# Scheduler\n",
        "num_update_steps_per_epoch = math.ceil(len(train_loader) / config.gradient_accumulation_steps)\n",
        "max_train_steps = config.num_train_epochs * num_update_steps_per_epoch\n",
        "lr_scheduler = get_scheduler(\n",
        "    config.learning_rate_scheduler_type,\n",
        "    optimizer=optm,\n",
        "    num_warmup_steps=config.learning_rate_warmup_steps,\n",
        "    num_training_steps=max_train_steps\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:29:46.204468Z",
          "iopub.execute_input": "2025-11-16T10:29:46.205183Z",
          "iopub.status.idle": "2025-11-16T10:29:46.209145Z",
          "shell.execute_reply.started": "2025-11-16T10:29:46.205157Z",
          "shell.execute_reply": "2025-11-16T10:29:46.208355Z"
        },
        "id": "HmmUrBMhWY2k"
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoder_1.to(acc.device)\n",
        "text_encoder_2.to(acc.device)\n",
        "# safety: use same dtype as training\n",
        "text_encoder_1.to(torch.float16)\n",
        "text_encoder_2.to(torch.float16)\n",
        "text_encoder_1.eval()\n",
        "text_encoder_2.eval()\n",
        "vae.eval()\n",
        "for p in vae.parameters():\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:50:36.732405Z",
          "iopub.execute_input": "2025-11-16T10:50:36.733263Z",
          "iopub.status.idle": "2025-11-16T10:50:36.753106Z",
          "shell.execute_reply.started": "2025-11-16T10:50:36.733229Z",
          "shell.execute_reply": "2025-11-16T10:50:36.752532Z"
        },
        "id": "_y-F1c3MWY2k"
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": [
        "def model_loss(unet_model, vae_model, te1, te2, noise_scheduler, batch):\n",
        "    device = acc.device\n",
        "    target_dtype = torch.float16 if config.mixed_precision == \"fp16\" else torch.float32\n",
        "\n",
        "    # 1. Input Prep\n",
        "    # Move pixels to GPU, but keep in float32 for the VAE\n",
        "    pixel_values = batch[\"pixel_values\"].to(device=device, dtype=torch.float32)\n",
        "    pixel_values = torch.nan_to_num(pixel_values, nan=0.0, posinf=1.0, neginf=0.0)\n",
        "    pixel_values = pixel_values.clamp(-1.0, 1.0)\n",
        "\n",
        "    input_ids_one = batch[\"input_ids_one\"].to(device)\n",
        "    input_ids_two = batch[\"input_ids_two\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 2.VAE Encoding\n",
        "        # Disable autocast to force the VAE to run in full float32 -> was giving main pain tbh\n",
        "        with torch.autocast(device.type, enabled=False, dtype=torch.float32):\n",
        "            enc = vae_model.encode(pixel_values)\n",
        "        #the above snippet will make sure that VAE runs on the GPU with float32!\n",
        "\n",
        "        if hasattr(enc, \"latent_dist\"):\n",
        "            latents = enc.latent_dist.sample()\n",
        "        elif isinstance(enc, torch.Tensor):\n",
        "            latents = enc\n",
        "        else:\n",
        "            raise RuntimeError(f\"Unexpected VAE.encode return type: {type(enc)}\")\n",
        "\n",
        "        # Latents are now on GPU in fp32.\n",
        "        # Scale and DOWNCAST them to fp16 for the UNet.\n",
        "        latents = (latents * vae_model.config.scaling_factor).to(dtype=target_dtype)\n",
        "        #scaled down using `latents*vae_model.config.scaling.factor` -> output is stll in float32\n",
        "        #target_dtype is float16 so .to() converts the above to that\n",
        "\n",
        "        # 3. text Encoding\n",
        "        # This will run in fp16 due to the accelerator's autocast\n",
        "        out1 = te1(input_ids_one, output_hidden_states=True)\n",
        "        out2 = te2(input_ids_two, output_hidden_states=True)\n",
        "\n",
        "        # penultimate hidden states\n",
        "        emb1 = out1.hidden_states[-2]\n",
        "        emb2 = out2.hidden_states[-2]\n",
        "\n",
        "        # correct pooled embedding\n",
        "        if hasattr(out2, \"text_embeds\"):\n",
        "            pooled_emb2 = out2.text_embeds\n",
        "        else:\n",
        "            pooled_emb2 = out2.hidden_states[-1][:, 0, :]\n",
        "            #pooled emb represents the sentecne as a whole and gives model a high level summary of the things\n",
        "\n",
        "        encoder_hidden_states = torch.cat([emb1, emb2], dim=-1)\n",
        "        #CLIP -> smaller model but efficent and OpenCLIP -> detailed and nuanced understanding of stuff --->> both get combined to give the model a better understanding of things\n",
        "\n",
        "    # Get batch size after VAE/Text encoding\n",
        "    bsz = latents.shape[0]\n",
        "\n",
        "    # 4. Noise and timesteps\n",
        "    noise = torch.randn_like(latents)\n",
        "    timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=device).long()\n",
        "    noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "    if config.debug:\n",
        "        # quick checks\n",
        "        if encoder_hidden_states.shape[0] != bsz:\n",
        "            raise RuntimeError(\"Batch size mismatch between latents and text embeddings.\")\n",
        "        if torch.isnan(encoder_hidden_states).any():\n",
        "            raise RuntimeError(\"NaN detected in encoder_hidden_states.\")\n",
        "\n",
        "    # 5. Conditioning\n",
        "    # `add_time_ids` must match the dtype of the text embeddings (fp16)\n",
        "    add_time_ids = torch.tensor(\n",
        "        [[config.resolution, config.resolution, 0, 0, config.resolution, config.resolution]] * bsz,\n",
        "        device=device,\n",
        "        dtype=target_dtype # <-- CHANGED (from torch.long)\n",
        "    )\n",
        "    added_cond_kwargs = {\"text_embeds\": pooled_emb2, \"time_ids\": add_time_ids}\n",
        "\n",
        "    # UNet - forward pass\n",
        "    model_out = unet_model(noisy_latents, timesteps, encoder_hidden_states, added_cond_kwargs=added_cond_kwargs)\n",
        "    model_pred = model_out.sample if hasattr(model_out, \"sample\") else model_out\n",
        "\n",
        "\n",
        "    loss = F.mse_loss(model_pred.float(), noise.float(), reduction=\"mean\")\n",
        "\n",
        "    if config.debug and (torch.isnan(loss) or torch.isinf(loss)):\n",
        "\n",
        "        raise RuntimeError(\n",
        "            \"Loss became NaN/Inf. Debug dump: \"\n",
        "            f\"model_pred min/max = {float(model_pred.float().min()):.6f}/{float(model_pred.float().max()):.6f}, \"\n",
        "            f\"noise min/max = {float(noise.float().min()):.6f}/{float(noise.float().max()):.6f}\"\n",
        "        )\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:58:07.643641Z",
          "iopub.execute_input": "2025-11-16T10:58:07.643981Z",
          "iopub.status.idle": "2025-11-16T10:58:07.655673Z",
          "shell.execute_reply.started": "2025-11-16T10:58:07.643953Z",
          "shell.execute_reply": "2025-11-16T10:58:07.655037Z"
        },
        "id": "yWzX3RujWY2k"
      },
      "outputs": [],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running single-batch dry-run to validate forward/backward steps...\")\n",
        "unet.train()\n",
        "batch = next(iter(train_loader))\n",
        "loss = model_loss(unet, vae, text_encoder_1, text_encoder_2, noise_scheduler, batch)\n",
        "print(\"Single-batch forward computed. Loss:\", float(loss.item()))\n",
        "\n",
        "acc.backward(loss)\n",
        "optm.step()\n",
        "optm.zero_grad()\n",
        "print(\"Backward + optimizer step carried out successfully (dry-run).\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T10:58:08.600871Z",
          "iopub.execute_input": "2025-11-16T10:58:08.601172Z",
          "iopub.status.idle": "2025-11-16T10:58:18.342274Z",
          "shell.execute_reply.started": "2025-11-16T10:58:08.601151Z",
          "shell.execute_reply": "2025-11-16T10:58:18.341486Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-isM8fUWY2l",
        "outputId": "6ee5e8e7-62f6-4d57-9d94-4d2467122934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running single-batch dry-run to validate forward/backward steps...\n",
            "Single-batch forward computed. Loss: 0.047874804586172104\n",
            "Backward + optimizer step carried out successfully (dry-run).\n"
          ]
        }
      ],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "global_step = 0\n",
        "unet.train()\n",
        "\n",
        "print(\"Deslaab\")\n",
        "\n",
        "for epoch in range(config.num_train_epochs):\n",
        "\n",
        "    # nice progress bar\n",
        "    epoch_pbar = tqdm(\n",
        "        train_loader,\n",
        "        desc=f\"Epoch {epoch+1}/{config.num_train_epochs}\",\n",
        "        disable=not acc.is_main_process\n",
        "    )\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    steps_in_epoch = 0\n",
        "    t0 = time()\n",
        "\n",
        "    for step, batch in enumerate(epoch_pbar):\n",
        "\n",
        "        with acc.accumulate(unet):\n",
        "            loss = model_loss(unet, vae, text_encoder_1, text_encoder_2, noise_scheduler, batch)\n",
        "\n",
        "            acc.backward(loss)\n",
        "\n",
        "            # Gradient clipping (safer)\n",
        "            acc.clip_grad_norm_(unet.parameters(), config.max_grad_norm)\n",
        "\n",
        "            optm.step()\n",
        "            lr_scheduler.step()\n",
        "            optm.zero_grad()\n",
        "\n",
        "        # Only log on sync steps (when optimizer actually stepped)\n",
        "        if acc.sync_gradients:\n",
        "            global_step += 1\n",
        "            steps_in_epoch += 1\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Print every 5 steps (adjust as needed)\n",
        "            if global_step % 5 == 0 and acc.is_main_process:\n",
        "                avg_loss = epoch_loss / steps_in_epoch\n",
        "                curr_lr = lr_scheduler.get_last_lr()[0]\n",
        "                step_time = (time() - t0) / max(1, steps_in_epoch)\n",
        "\n",
        "                epoch_pbar.set_postfix({\n",
        "                    \"loss\": f\"{avg_loss:.4f}\",\n",
        "                    \"lr\": f\"{curr_lr:.2e}\",\n",
        "                    \"step_time\": f\"{step_time:.2f}s\"\n",
        "                })\n",
        "\n",
        "            # Save checkpoint\n",
        "            if global_step % config.save_every_step == 0 and acc.is_main_process:\n",
        "                ckpt_path = f\"{config.checkpointsDir}/checkpoint-{global_step}\"\n",
        "                acc.save_state(ckpt_path)\n",
        "                print(f\"Saved checkpoint at: {ckpt_path}\\n\")\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    if acc.is_main_process:\n",
        "        print(f\"Finished Epochhhh {epoch+1}/{config.num_train_epochs} | \"\n",
        "              f\"Avg Loss: {epoch_loss/steps_in_epoch:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD2IcwH0cycQ",
        "outputId": "ef8953fa-e48f-4dd1-d26d-0f7b60b95515"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deslaab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3:  82%|████████▏ | 1000/1221 [25:29<06:06,  1.66s/it, loss=0.1053, lr=7.19e-05, step_time=6.12s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint at: /content/drive/MyDrive/Naruto_FineTune/checkpoints/checkpoint-250\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 1221/1221 [31:04<00:00,  1.53s/it, loss=0.1047, lr=1.00e-04, step_time=6.11s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Epochhhh 1/3 | Avg Loss: 0.1047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3:  64%|██████▍   | 779/1221 [19:45<11:39,  1.58s/it, loss=0.0959, lr=2.13e-05, step_time=6.08s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint at: /content/drive/MyDrive/Naruto_FineTune/checkpoints/checkpoint-500\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 1221/1221 [30:52<00:00,  1.52s/it, loss=0.0989, lr=9.97e-05, step_time=6.06s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Epochhhh 2/3 | Avg Loss: 0.0989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3:  46%|████▌     | 558/1221 [14:04<16:32,  1.50s/it, loss=0.0898, lr=2.72e-07, step_time=6.03s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint at: /content/drive/MyDrive/Naruto_FineTune/checkpoints/checkpoint-750\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 1221/1221 [31:25<00:00,  1.54s/it, loss=0.0971, lr=9.90e-05, step_time=6.17s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Epochhhh 3/3 | Avg Loss: 0.0971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "\n",
        "#Save\n",
        "final_save_path = \"/content/drive/MyDrive/Naruto_FineTune/final_weights\"\n",
        "os.makedirs(final_save_path, exist_ok=True)\n",
        "\n",
        "unet = acc.unwrap_model(unet)\n",
        "unet.save_pretrained(final_save_path)\n",
        "print(f\" Final weights saved safely to: {final_save_path}\")\n",
        "\n",
        "#Clean VRAM\n",
        "print(\"Cleaning up training models from VRAM...\")\n",
        "try:\n",
        "    del unet, text_encoder_1, text_encoder_2, vae, optm, acc\n",
        "except NameError:\n",
        "    print(\"Some models were already deleted.\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"Training complete and LoRA weights saved.\")\n",
        "print(\"Memory cleared. Ready for inference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL2FOZSjfJ6y",
        "outputId": "0fa2f8a5-3a9c-4e98-d404-edb97fa304c9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Final weights saved safely to: /content/drive/MyDrive/Naruto_FineTune/final_weights\n",
            "Cleaning up training models from VRAM...\n",
            "Training complete and LoRA weights saved.\n",
            "Memory cleared. Ready for inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NYcKjrjpnDml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
}